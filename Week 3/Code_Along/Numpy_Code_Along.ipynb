{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ethanmccartney/Downloads/Code_Along/Numpy_Code_Along.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ethanmccartney/Downloads/Code_Along/Numpy_Code_Along.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ethanmccartney/Downloads/Code_Along/Numpy_Code_Along.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ethanmccartney/Downloads/Code_Along/Numpy_Code_Along.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ethanmccartney/Downloads/Code_Along/Numpy_Code_Along.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39mset_printoptions(suppress\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>NumPy is Python's most used library for efficient numerical computations. At the core of numpy lies the N-dimensional array data structure (also called a numpy array).</p>\n",
    "\n",
    "<p>An array is defined by the <strong>type</strong> of elements it contains and its <strong>shape</strong>. For instance, a matrix may be represented as an array of shape (<em>N</em> x <em>M</em>). Note, that numpy arrays can have arbirary shape (<em>Dim1</em>, <em>Dim2</em>, <em>Dim3</em>,...).</p> \n",
    "\n",
    "<div>\n",
    "<img src=\"https://predictivehacks.com/wp-content/uploads/2020/08/numpy_arrays-1024x572.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<p>Besides being a convenient data container, numpy arrays provide an interface to many <strong>vectorized</strong> operations, implemented in native C code. Vectorization in interpreted languages is a means to speed up repetitive computations (elementwise operations, etc.). Thus, vectorization saves your time and makes you more productive!</p>\n",
    "\n",
    "For more information about the nuts and bolts of numpy, check out the very well writte numpy documentation:\n",
    "https://docs.scipy.org/doc/numpy/user/quickstart.html\n",
    "\n",
    "Also, check out this very informative tutorial paper:\n",
    "https://arxiv.org/pdf/1102.1523.pdf\n",
    "\n",
    "<p>Now, let's get some hands-on experience with numpy arrays!</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers in a given range (from:to:step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly spaced items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform numbers [0 - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random integers (low - high, high is exclusive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally distributed random numbers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random matrix\n",
    "\n",
    "# Save compressed\n",
    "\n",
    "# Save uncompressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a compressed array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and attributes of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the type of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the total number of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find min, max, argmax, argmin, mean, std, etc...\n",
    "print('Minimum value: ', arr.min())\n",
    "print('Maximum value: ', arr.max())\n",
    "print('Index of minimum value: ', arr.argmin())\n",
    "print('Index of maximum value: ', arr.argmax())\n",
    "\n",
    "print('----------------------------')\n",
    "\n",
    "# Alternatively, you could use the \"functional grammer\" of numpy\n",
    "print('Minimum value: ', np.min(arr))\n",
    "print('Maximum value: ', np.max(arr))\n",
    "print('Index of minimum value: ', np.argmin(arr))\n",
    "print('Index of maximum value: ', np.argmax(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about nd arrays? (axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and selection of numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing 1D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing a range of numbers (similar to slicing python lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From index (inclusive) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a slice to a variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing ND arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean array (array of 0s and 1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index with a boolen array (keep only elements whose index corresponds to True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Time for a short exercise!</strong></p>\n",
    "\n",
    "Suppose you have a matrix which contains the response times of 50 participants, where each row represents an individual participant.\n",
    "Your data contains missing values, coded as '999' by your student assistant. Your want to take a quick look at the data by:\n",
    "\n",
    "1. Loading the file \"rt_missing.txt\"\n",
    "2. Replacing all 999 values with the value np.nan\n",
    "3. Computing the mean and variance of the the response times for each participant<br>\n",
    "\n",
    "Hint: try to use `np.mean()` and `np.var()` to see what happens and look for a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = None\n",
    "variances = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code\n",
    "f, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.histplot(means, ax=axarr[0], color='#aa0000', alpha=0.6)\n",
    "sns.histplot(np.sqrt(variances), ax=axarr[1], color='#0000aa', alpha=0.6)\n",
    "\n",
    "for ax in axarr:\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_xlabel('Response time (seconds)')\n",
    "axarr[0].set_title('Response Time Means', fontsize=14)\n",
    "axarr[1].set_title('Response Time Standard Deviations', fontsize=14)\n",
    "axarr[1].set_ylabel('')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar-array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All scalar-array algebraic operations are performed element-wise\n",
    "\n",
    "\n",
    "# Multiplication by a scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of a scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array-array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can perform all usual linear algebra operations on numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementwise multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementwise addition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Matrix Multiplication Memo :)</strong><p>\n",
    "    \n",
    "![Matrix Multiplication Memo](https://www.mathsisfun.com/algebra/images/matrix-multiply-a.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matmul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.random.rand(1000)\n",
    "u2 = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed comparison between vectorized operations and pure Python loops\n",
    "# We use the \"magic\" keyword time to to estimate running time of a cell\n",
    "# Dot product\n",
    "%timeit u1 @ u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive implementation of the dot product\n",
    "def dot_product(v1, v2):\n",
    "    \"\"\"Naive dot product implementation.\"\"\"\n",
    "    \n",
    "    p = 0\n",
    "    for i in range(len(v1)):\n",
    "        p += v1[i] * v2[i]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential, log, etc (it's all performed elementwise!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: OLS Regression with numpy\n",
    "\n",
    "<p>In this exercise, we will compute the parameters (weights) of an OLS regression using only numpy (and our linear algebra knowledge).</p>\n",
    "<p>The forward equation for OLS regression is given by:</p>\n",
    "\n",
    "$$\\hat{y} = \\mathbf{X}\\beta$$\n",
    "\n",
    "where $\\mathbf{X}$ is an $N{\\times}M$ matrix of covariates, and $\\beta$ is a vector of parameters estimated from the data. In OLS regression, we seek to minimize the MSE (mean squared error) criterion:\n",
    "\n",
    "$$MSE(\\beta) = \\frac{1}N\\sum_{i=1}^N(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "<p>which can be written in matrix form as</p>\n",
    "\n",
    "$$MSE(\\beta) = (y - \\mathbf{X}\\beta)^T(y - \\mathbf{X}\\beta)$$\n",
    "\n",
    "setting the gradient of the MSE criterion to zero and solving for $y$, we obtain the following solution which minimizes the MSE:<br>\n",
    "\n",
    "$$\\beta^* = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^Ty$$\n",
    "\n",
    "See this excellent post for a full derivation: https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression\n",
    "\n",
    "Thus, in order to complete this exercise, you need to follow these steps:\n",
    "1. Generate X (covariates) and y (outcome) by calling the `simulate_ols_data()` function\n",
    "2. Complete the `ols(X, y)` function by computing the solution to the normal equation\n",
    "3. Compare your best parameters with the parameters returned by the numpy function `numpy.linalg.lstsq(X, y)`\n",
    "4. Compute RMSE on the training data by completing the function `rmse(y, y_hat)`. The RMSE is given by:\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$RMSE= \\sqrt{\\frac{1}N\\sum_{i=1}^N(y_i - \\hat{y_i})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ols_data(N=100, M=3):\n",
    "    \"\"\"Function to simulate synthetic regression data.\"\"\"\n",
    "    \n",
    "    # Generate design matrix\n",
    "    X = np.random.randn(N, M)\n",
    "\n",
    "    # Add intercept to model\n",
    "    X = np.c_[np.ones(shape=(N, 1)), X]\n",
    "\n",
    "    # Generate true beta ~ N(0, 1)\n",
    "    beta_true = np.random.randn(M + 1)\n",
    "\n",
    "    # Compute noisy linear function\n",
    "    y = X @ beta_true + np.random.randn(N)\n",
    "\n",
    "    return X, y, beta_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinary_least_squares(X, y):\n",
    "    \"\"\"Function to compute the parameters of an OLS regression.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    \"\"\"Function to compute the RMSE between predictions and outcomes.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simulate regression data\n",
    "X, y, beta_true = simulate_ols_data(N=10000)\n",
    "\n",
    "# 2. Obtain best parameters\n",
    "beta_hat = ordinary_least_squares(X, y)\n",
    "\n",
    "# 3. Obtain best parameters using numpy.linalg.lstsq\n",
    "beta_hat_np = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "# 4. Compute RMSE on training data\n",
    "y_hat = X @ beta_hat_np\n",
    "\n",
    "rmse_train = rmse(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True betas: ', beta_true)\n",
    "print('OLS betas: ', beta_hat)\n",
    "print('Numpy LSTSQ betas', beta_hat_np)\n",
    "print('RMSE train: ', rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside on plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some personality dataset containing raw data from the International Personality Item Pool designed to measure Cattell's 16 personality factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exercise: PCA\n",
    "\n",
    "![PCA meme](https://media.makeameme.org/created/brace-yourself-pca.jpg)\n",
    "\n",
    "<p>PCA learns a representation of multidimensional data which has lower dimensionality than the original data.</p>\n",
    "Furthermore is an orthogonal linear projection of the data, meaning that it decorrelates the dimensions of the learned representation.\n",
    "\n",
    "Consider a data matrix $\\mathbf{X}$. Suppose further that the data has been standardized (centered and scaled). The unbiased estimate of the covariance matrix is given by:\n",
    "\n",
    "$$\\widehat{Cov}[\\mathbf{X}] = \\frac{1}{m - 1}\\mathbf{X}^T\\mathbf{X}$$\n",
    "\n",
    "A popular variant of PCA performs an eigendecomposition of $\\mathbf{X}^T\\mathbf{X}$ defined by:\n",
    "\n",
    "$$\\widehat{Cov}[\\mathbf{X}] = \\mathbf{V}\\mathbf{\\Lambda}\\mathbf{V}^T$$\n",
    "\n",
    "where $\\mathbf{V}$ is the matrix of <em>eigenvectors</em> of $\\widehat{Cov}[\\mathbf{X}]$ and $\\mathbf{\\Lambda}$ is a diagonal matrix of <em>eigenvalues</em>.\n",
    "\n",
    "(Note, that sometimes the decomposition is performed on the scatter matrix instead $\\mathbf{X}^T\\mathbf{X}$. This does not change the eigenvectors, but simply scales the eigenvalues.) \n",
    "\n",
    "In other words, we decompose the covariance matrix into a scale part (eigenvalues) and direction part (eigenvectors). The eigenvectors are the principle components of the $\\widehat{Cov}[\\mathbf{X}]$.\n",
    "\n",
    "Eigenvectors determine orthogonal directions in feature space. Each component of the eigenvector encodes how each of the original dimension directions contributes to the eigenvector. The first eigenvector (first PC) encodes the direction of most variance, and so on.\n",
    "Eigenvalues represent how much of the original variance is captured (explained) in the direction of the corresponding eigenvector.\n",
    "\n",
    "Read in the data `extraversion_big5.csv` and complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('extraversion_big5.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "### Your code here\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov = None\n",
    "\n",
    "# Perform an eigendecomposition\n",
    "### Your code here\n",
    "lambd, V = None, None\n",
    "\n",
    "# Check reconstruction of the covariance matrix\n",
    "np.allclose(V @ np.diag(lambd) @ V.T, cov) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(np.arange(1, lambd.shape[0]+1), lambd / np.sum(lambd), '-o', color='#aa0000')\n",
    "ax.set_xlim([1 - 0.1, 10 + 0.1])\n",
    "ax.set_xlabel('Eigenvalue index')\n",
    "ax.set_ylabel('Proportion of explained variance')\n",
    "ax.set_title('Eigenvalues plot')\n",
    "ax.grid(alpha=0.3)\n",
    "sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "421px",
    "width": "410px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
